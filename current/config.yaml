# Model Architecture
model:
  base_size: 1280 # ESM2 embedding dimensions
  hidden_size: 128
  n_layers: 1 # Number of encoder and decoder layers
  n_heads: 8 # Number of attention heads
  intermediate_size: 512
  dropout: 0.2
  max_sequence_length: 1024  # Maximum sequence length for input data
  activation_function: "swish" # Options ["relu", "gelu", "swish", "elu", "leaky_relu", "mish"]
  gp_layer:
    rffs: 4096
    out_targets: 1
    gp_cov_momentum: -1
    gp_ridge_penalty: 1
    likelihood_function: 'binary_logistic'

# Training Parameters
training:
  batch_size: 16
  learning_rate: 0.0001
  weight_decay: 0.00001
  iteration: 14
 
optimizer:
  step_size: 2
  gamma: 0.93


# Other Parameters 
other:
  random_seed: 47  # Chirp chirp!
  cuda_device: 'cuda' # Change if necessary, select the cuda device available on your setup.